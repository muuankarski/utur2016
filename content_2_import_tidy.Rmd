---
title: "Datan tuominen ja siivoaminen"
output: 
  html_document: 
    toc: true
    toc_float: true
    number_sections: yes
    code_folding: show
---

```{r setup}
library(knitr)
knitr::opts_chunk$set(list(echo=TRUE,
                           eval=TRUE,
                           cache=TRUE,
                           warning=FALSE,
                           message=FALSE))
opts_chunk$set(fig.width = 10, fig.height = 6)
```





# Ennakkotehtävät


## Lue


- R Data Import/Export <https://cran.r-project.org/doc/manuals/r-devel/R-data.html> *This is a guide to importing and exporting data to and from R.*
- - R for Data Science: Data import <http://r4ds.had.co.nz/data-import.html>



## Katso


- Getting Data into R <https://vimeo.com/130548869> 0.00 -> 



# Datan tuominen & datalähteet

## Paketteja datan lukemiseen eri datalähteistä

These packages help you import data into R and save data.

* [feather](https://blog.rstudio.org/2016/03/29/feather/) - a fast, lightweight file format used by both R and Python
* [readr](https://blog.rstudio.org/2015/10/28/readr-0-2-0/) - reads tabular data
* [readxl](https://blog.rstudio.org/2015/04/15/readxl-0-1-0/) - reads Microsoft Excel spreadsheets
* [openxlsx](https://github.com/awalker89/openxlsx) - reads Microsoft Excel spreadsheets
* [googlesheets](https://github.com/jennybc/googlesheets) - reads Google spreadsheets
* [haven](https://blog.rstudio.org/2015/03/04/haven-0-1-0/) - reads SAS, SPSS, and Stata files
* [httr](https://blog.rstudio.org/2016/02/02/httr-1-1-0/) - reads data from web APIs
* [rvest](https://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/) - scrapes data from web pages
* [xml2](https://github.com/hadley/xml2) - reads HTML and XML data
* [webreadr](https://cran.r-project.org/web/packages/webreadr/vignettes/Introduction.html) - reads common web log formats
* [DBI](https://github.com/rstats-db/DBI) - a universal interface to database management systems (DBMS)
    + [RMySQL](https://github.com/rstats-db/RMySQL) - MySQL driver for DBI
    + [RPostgres](https://github.com/rstats-db/RPostgres) - Postgres driver for DBI
    + [RSQLite](https://github.com/rstats-db/RSQLite) - SQlite driver for DBI
    + [bigrquery](https://github.com/rstats-db/bigrquery) - Google BigQuery driver for DBI
* [PivotalR](https://github.com/pivotalsoftware/PivotalR) - reads data from and interfaces with [Postgres](http://www.postgresql.org), [Greenplum](http://greenplum.org), and [HAWQ](http://hawq.incubator.apache.org) 
* [dplyr](https://github.com/hadley/dplyr) - contains an interface to common databases
* [data.table](https://github.com/Rdatatable/data.table) - `fread()` for fast table reading
* [git2r](https://github.com/ropensci/git2r) - tools to access git repositories




## Paikalliset data ie. datan lukeminen levyltä

| Data | Paketti | Vaihtoehdot |
| ---  | ------  | ---------   |
| tilasto-ohjelmat   | [haven]()  | [foreign](), [sas7bdat](), [readstata13]() |
| Excel               | [readxl]() | [gdata](), [openxlsx](), [XLConnect](), [xlsx]() |
| Tekstidatat         | [readr]()  | [base](), [data.table]() |


## Datan lukeminen tietokannoista

- [DBI](https://cran.r-project.org/web/packages/DBI/index.html) A database interface definition for communication between R and relational database management systems



```{r dbi, eval=FALSE}
# 1) Load the DBI package
library(DBI)

# 2) Connect to a spesific database
db <- dbConnect(RPostgres::Posgres(), user, pass, ...)
db <- dbConnect(RMySQL::MySQL(), user, pass, ...)
db <- dbConnect(RSQLite::::SQLite(), path)

# 3) Execute a query
dbGetQuery(db, "SELECT * FROM mtcars")

# 4) Be polite and close connection
dbDisconnect(db)
```


- The dplyr databases vignette - CRAN <https://cran.r-project.org/web/packages/dplyr/vignettes/databases.html>
- IBM: Using R with databases <https://www.ibm.com/developerworks/data/library/techarticle/dm-1402db2andr/>

## Datan lukeminen tilastotietokantojen rajapinnoista


- UseR2016: Karthik Ram, Garrett Grolemund and Scott Chamberlain: Extracting data from the web APIs and beyond <https://github.com/ropensci/user2016-tutorial#extracting-data-from-the-web-apis-and-beyond>
    - pdf <https://github.com/ropensci/user2016-tutorial/raw/master/slides.pdf>


- [sotkanet](https://cran.r-project.org/web/packages/sotkanet/index.html) Tools for Sotkanet Open Data Portal
- [pxweb](https://cran.r-project.org/web/packages/pxweb/index.html) R Interface to the PX-Web/PC-Axis API (Tilastokeskus, Statistics Sweden etc.)
- [eurostat](https://cran.r-project.org/web/packages/eurostat/index.html) Tools to download data from the Eurostat database <http://ec.europa.eu/eurostat> together with search and manipulation utilities.
- [WDI](https://cran.r-project.org/web/packages/WDI/index.html) Search, extract and format data from the World Bank's World Development Indicators
- [FAOSTAT](https://cran.r-project.org/web/packages/FAOSTAT/index.html) Download Data from the FAOSTAT Database of the Food and Agricultural Organization (FAO) of the United Nations
- [imfr](https://cran.r-project.org/web/packages/imfr/index.html) - Explore and download data from the International Monetary Fund's data API <http://data.imf.org/>.


## Datan raapiminen verkosta

- [rvest](https://cran.r-project.org/web/packages/rvest/index.html) Easily Harvest (Scrape) Web Pages
    - [Selectorgadget](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html)


```{r rvest}
library(httr)
x <- httr::GET("http://vetu.kapsi.fi/webbi/")
x$status_code
x$headers
# x$content
```

```{r get}

httr::GET("https://httpbin.org/get")

x <- httr::GET("https://httpbin.org/get", query = list(a = 5))
x <- httr::GET("https://httpbin.org/get", add_headers(wave = "hi"))
x <- httr::POST("https://httpbin.org/post", body = list(a = 5))
x
```


```{r post}
httr::POST("https://httpbin.org/post")
```

```{r getget}
z <- httr::GET("http://httpbin.org/get")
code <- z$status
httr::http_status(code)

z <- httr::GET("http://httpbin.org/status/200")

```


```{r json}
library(jsonlite)
fromJSON('{"foo":"bar"}')
fromJSON('{"foo":"bar"}', FALSE)
fromJSON('[{"foo":"bar","hello":"world"}]')

```


```{r xmlxml}
library(xml2)
res <- read_xml('<foo>bar</foo>')
xml_name(res)
xml_text(res)

```


```{r imbd}
j1 <- GET("http://www.omdbapi.com/?t=iron%20man%202&r=json")
content(j1, as = 'text')
content(j1, as = 'parsed')
```


```{r xml}
x1 = GET('http://www.omdbapi.com/?t=iron%20man%202&r=xml')
content(x1, as = 'text')
content(x1, as = 'parsed')
```


```{r webcall}
web_call <- GET('http://swapi.co/api/planets/1/')
web_call
```

```{r apiapi}
web_call <- GET('api.randomuser.me')
web_call

web_call <- GET('api.openweathermap.org/data/2.5/forecast?id=524901')
web_call

```


```{r apiapiapi}
person <- GET('api.randomuser.me')
txt <- content(person, as = "text")
prsd <- content(person, as = "parsed")


# monta
num_results <- 5
args <- list(results = num_results)
random_names <- GET("http://api.randomuser.me/", query = args)
output <- content(random_names, as = 'parsed')
length(output$results)

output$results[[1]]$email

args <- list(results = 5)
random_names <- GET("http://api.randomuser.me/", query = args)
output <- content(random_names, as = 'parsed')
length(output$results)

args <- list(gender="female",results=10,format="csv")
random_names <- GET("http://api.randomuser.me/", query = args)
output <- content(random_names, as = 'parsed')
length(output$results)

output$results[[2]]$email


```


----


# Datapaketteja

These packages contain data sets to use as training data or toy examples.

* [babynames](https://github.com/hadley/babynames) - Names given to US babies 1880-2014
* [neiss](https://github.com/hadley/neiss) - sample of all accidents reported to US emergency rooms 2009-2014
* [yrbss](https://github.com/hadley/yrbss) - Youth Risk Behaviour Surveillance System data from 1991 to 2013
* [nycflights13](https://github.com/hadley/nycflights13) - all out-bound flights from NYC in 2013
* [hflights](https://github.com/hadley/hflights) - flights departing Houston in 2011
* [USAboundaries](https://github.com/ropensci/USAboundaries) - Historical and Contemporary Boundaries of the United States of America
* [rworldmap](https://github.com/AndySouth/rworldmap) - country border data
* [usdanutrients](https://github.com/hadley/usdanutrients) - USDA nutrient database
* [fueleconomy](https://github.com/hadley/fueleconomy) - EPA fuel economy data
* [nasaweather](https://github.com/hadley/nasaweather) - geographic and atmospheric measures on a very coarse 24 by 24 grid covering Central America
* [mexico-mortality](https://github.com/hadley/mexico-mortality) - deaths in Mexico
* [data-movies](https://github.com/hadley/data-movies) and [ggplotmovies](https://cran.r-project.org/web/packages/ggplot2movies/) - data from the Internet Movie Database (IMDB)
* [pop-flows](https://github.com/hadley/pop-flows) - Population flows around the USA in 2008
* [data-housing-crisis](https://github.com/hadley/data-housing-crisis) - Clean data related to the 2008 US housing crisis
* [gun-sales](https://github.com/NYTimes/gunsales) - Statistical analysis of monthly background checks of gun purchases from NY times
* [stationaRy](https://github.com/rich-iannone/stationaRy) - hourly meteorological data from one of thousands of global stations
* [gapminder](https://github.com/jennybc/gapminder) - Excerpt from the Gapminder data
* [janeaustenr](https://github.com/juliasilge/janeaustenr) - Jane Austen's Complete Novels



# "Datan siivoaminen"


## Lue

- [Wickham, Hadley. 2014. ‘Tidy Data’. Journal of Statistical Software 59 (10). doi:10.18637/jss.v059.i10.
](http://vita.had.co.nz/papers/tidy-data.html)
- R for Data Science: Tidy Data <http://r4ds.had.co.nz/tidy-data.html>

- tidyr-paketin vignette: <https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html>
- Rstudio blog: Introducing tidyr <https://blog.rstudio.org/2014/07/22/introducing-tidyr/>
- Data Wrangling Cheat Sheet - RStudio  <https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf>



## Katso

- Getting Data into R <https://vimeo.com/130548869>

## Paketit

## Tidy
These packages help you wrangle your data into a form that is easy to analyze in R.

* [tidyr](https://github.com/hadley/tidyr) - tools for tidying layout of tabular data
* [dplyr](https://github.com/hadley/dplyr) - tools for joining multiple tables into a tidy data set
* [purrr](https://github.com/hadley/purrr) - tools for applying R functions to data structures, very useful when tidying
* [broom](http://varianceexplained.org/r/broom-intro/) - tools for tidying statistical models into data frames
* [zoo](https://www.google.com/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=r%20zoo) - data structures for time series data
* [PivotalR](https://github.com/pivotalsoftware/PivotalR) - R wrappers for in-database SQL operations (i.e. join, group by)



# Kotitehtävä



